# Multi-layer Perceptron (MLP)

This repository contains a multi-layered perceptron (artificial neural network) programmed from scratch.

Customisable MLP parameters:
- Number of input
- Number of ouputs
- Number of hidden layers
- Number of neurons in each layer
- Activation Functions (sigmoid, tanh, Relu, softmax)
- Number of traning epoch
- Learning rate

The MLP uses Stochastic Gradient Descent for backpropagation and cross entropy for loss function. 
Dataset is the Banknote authentication dataset obtained from: https://archive.ics.uci.edu/ml/datasets/banknote+authentication.
